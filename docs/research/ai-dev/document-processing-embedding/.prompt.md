<BRIEF> I need thorough research on document preprocessing and embedding generation for RAG systems. I want to understand chunking strategies, metadata handling, and embedding models that work well locally and via API. </BRIEF> 

==== BEGIN DEEP RESEARCH PROMPT ==== 

Researcher Role: AI systems specialist focused on retrieval-augmented generation. Scope: Explore both local and API-based embeddings, chunking techniques, and metadata strategies. Cover open-source and commercial options. Research Dimensions: Fundamentals of document chunking and embeddings Options: LangChain, LlamaIndex, SentenceTransformers, OpenAI ada-002 Trade-offs: chunk size vs retrieval quality, local vs API embeddings Best Practices: metadata handling, incremental indexing Case Studies: Perplexity, Microsoft GraphRAG, Stanford STORM Open Questions: optimal chunk size, handling multi-format docs Evaluation Rubric: Accuracy / effectiveness Performance / scalability Ease of implementation Ecosystem maturity Cost Outputs Required: Inventory of chunking + embedding methods Comparison table of embedding options Best practices summary Open challenges Cited evidence 

==== END DEEP RESEARCH PROMPT ====