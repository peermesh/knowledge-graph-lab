<BRIEF>
I need research on retrieval + generation pipelines for RAG, with focus on semantic similarity search, prompt templates, citations, and caching.
</BRIEF>

==== BEGIN DEEP RESEARCH PROMPT ====
Researcher Role: AI pipeline engineer.

Scope: Explore end-to-end RAG pipelines, including retrieval, generation, and caching.

Research Dimensions:

Fundamentals: how retrieval â†’ generation works

Options: LangChain RAG, LlamaIndex Q&A, Haystack

Trade-offs: top-k values, context length vs speed

Best Practices: prompt templates, citation handling, caching

Case Studies: Perplexity (low latency), Microsoft GraphRAG

Open Questions: multi-hop queries, hallucination prevention

Evaluation Rubric:

Answer quality

Latency

Ease of orchestration

Cost implications

Maintainability

Outputs Required:

RAG pipeline options

Comparison matrix

Best practices summary

Open risks

Cited evidence
==== END DEEP RESEARCH PROMPT ====